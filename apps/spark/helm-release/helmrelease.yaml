apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: spark
  namespace: spark
spec:
  interval: 15m
  chart:
    spec:
      chart: spark
      sourceRef:
        kind: HelmRepository
        name: bitnami-spark
        namespace: flux-system
  install:
    timeout: 15m0s
  upgrade:
    timeout: 15m0s
  postRenderers:
    - kustomize:
        images:
          - name: docker.io/bitnami/spark
            newName: docker.io/bitnamilegacy/spark
            newTag: "3.5.0"
  values:
    # Use bitnamilegacy Spark image
    image:
      registry: docker.io
      repository: bitnamilegacy/spark
      tag: "3.5.0"
    
    # Skip container image verification for non-standard images
    global:
      security:
        allowInsecureImages: true
    
    # Delta Lake and S3 configuration
    extraEnvVars:
      - name: SPARK_EXTRA_CLASSPATH
        value: "/opt/bitnami/spark/jars/*"
      - name: AWS_ACCESS_KEY_ID
        value: "minio"
      - name: AWS_SECRET_ACCESS_KEY
        value: "minio123"
    
    # Spark configuration for Delta Lake and S3
    configuration: |
      spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
      spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
      spark.hadoop.fs.s3a.endpoint=http://minio.minio.svc.cluster.local:9000
      spark.hadoop.fs.s3a.access.key=minio
      spark.hadoop.fs.s3a.secret.key=minio123
      spark.hadoop.fs.s3a.path.style.access=true
      spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      spark.hadoop.fs.s3a.connection.ssl.enabled=false
    
    # Master configuration
    master:
      replicaCount: 1
      resources:
        requests:
          cpu: "100m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      persistence:
        enabled: true
        storageClass: local-path
        size: 10Gi
    
    # Worker configuration
    worker:
      replicaCount: 1
      resources:
        requests:
          cpu: "100m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      persistence:
        enabled: true
        storageClass: local-path
        size: 20Gi
    
    # Ingress for Spark UI
    ingress:
      enabled: true
      ingressClassName: nginx
      hostname: spark.vanir-proxmox.duckdns.org
      path: /
      pathType: Prefix
    
    # Metrics for Prometheus
    metrics:
      enabled: true
      masterAnnotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
      workerAnnotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8081"

